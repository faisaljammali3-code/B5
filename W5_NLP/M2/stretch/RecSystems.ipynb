{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce_slcsdcQnz"
   },
   "source": [
    "# Embeddings for Recommendation Systems\n",
    "\n",
    "As we’ve mentioned, the concept of embeddings is useful in so many other domains. In industry, it’s widely used for recommendation systems, for example.\n",
    "\n",
    "we’ll use the word2vec algorithm to embed songs using human-made music playlists. Imagine if we treated each song as we would a word or token, and we treated each playlist like a sentence. These embeddings can then be used to recommend similar songs that often appear together in playlists.\n",
    "\n",
    "The dataset we’ll use was collected by Shuo Chen from Cornell University. It contains playlists from hundreds of radio stations around the US. Figure 2-17 demonstrates this dataset.\n",
    "\n",
    "![Three playlists containing watched video IDs](../assets/videos_playlists.png)\n",
    "\n",
    "Figure 2-17. For video embeddings that capture video similarity we’ll use a dataset made up of a collection of playlists, each containing a list of videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvGzcLOhdhYv"
   },
   "source": [
    "Let’s demonstrate the end product before we look at how it’s built. So let’s give it a few songs and see what it recommends in response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QcGQCEAdky_"
   },
   "source": [
    "### Training a Song Embedding Model\n",
    "\n",
    "We’ll start by loading the dataset containing the song playlists as well as each song’s metadata, such as its title and artist:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwJc8vMGcNBx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "# Get the playlist dataset file\n",
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
    "\n",
    "# Parse the playlist dataset file. Skip the first two lines as\n",
    "# they only contain metadata\n",
    "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
    "\n",
    "# Remove playlists with only one song\n",
    "playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]\n",
    "\n",
    "# Load song metadata\n",
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
    "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
    "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
    "songs_df = songs_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1S039eE-ctiR",
    "outputId": "8a19f2a4-b0fd-4051-be66-3f842ebc781b"
   },
   "outputs": [],
   "source": [
    "print( 'Playlist #1:\\n ', playlists[0], '\\n')\n",
    "print( 'Playlist #2:\\n ', playlists[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the official [Gensim Word2Vec documentation](https://radimrehurek.com/gensim/models/word2vec.html), here is the description for each parameter, of the next code snippet calling `Word2Vec`:\n",
    "\n",
    "* **`sentences` (playlists):** The input data. It must be an iterable of lists of tokens (in your case, song IDs or names within a playlist).\n",
    "* **`vector_size=32`:** The dimensionality of the word vectors. This defines the number of features in the hidden layer of the neural network used to represent each item.\n",
    "* **`window=20`:** The maximum distance between the current and predicted word within a sentence. A larger window captures more global context.\n",
    "* **`negative=50`:** Specifies how many \"noise words\" should be drawn for **Negative Sampling**. According to the documentation, values between 5 and 20 are typical for small datasets, while 2 to 5 suffice for large ones. You have set this high (50) to increase training rigor.\n",
    "* **`min_count=1`:** The model ignores all words with a total frequency lower than this. Setting it to 1 ensures every item in your playlists is included in the vocabulary.\n",
    "* **`workers=4`:** The number of worker threads used to train the model, allowing for multicore parallelization to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQQMZdpbcwOK"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train our Word2Vec model\n",
    "model = Word2Vec(\n",
    "    playlists,\n",
    "    vector_size=32,\n",
    "    window=20,\n",
    "    negative=50,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8yH27BrcxfK",
    "outputId": "9551b152-242f-410f-dd90-007a2fa4219c"
   },
   "outputs": [],
   "source": [
    "song_id = 2172\n",
    "\n",
    "# Ask the model for songs similar to song #2172\n",
    "model.wv.most_similar(positive=str(song_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gsp5mknLczPW",
    "outputId": "cca68869-8675-4b1c-922a-bbe17a54d990"
   },
   "outputs": [],
   "source": [
    "print(songs_df.iloc[2172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "zcMPAXZ6c0wm",
    "outputId": "439b7e0e-0800-49c7-b3c5-39389e1675fa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_recommendations(song_id):\n",
    "    similar_songs = np.array(\n",
    "        model.wv.most_similar(positive=str(song_id),topn=5)\n",
    "    )[:,0]\n",
    "    return  songs_df.iloc[similar_songs]\n",
    "\n",
    "# Extract recommendations\n",
    "print_recommendations(2172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "ybkpP2xGdBGK",
    "outputId": "e8934a29-f74a-4f1b-94e8-2c8cda4ac927"
   },
   "outputs": [],
   "source": [
    "print_recommendations(2172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "LAfQciFEdB15",
    "outputId": "fad15024-a9e8-4a4a-846a-6d856e83de65"
   },
   "outputs": [],
   "source": [
    "print_recommendations(842)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
