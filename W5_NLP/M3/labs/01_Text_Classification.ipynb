{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLgiaHcfxkWH"
      },
      "source": [
        "# Text Classification Lab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HassanAlgoz/B5/blob/main/W5_NLP/M3/labs/01_Text_Classification.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook explores three different approaches to text classification using pre-trained models:\n",
        "1. **Task-specific models**: Using models fine-tuned for sentiment analysis\n",
        "2. **Embedding models + Classifier**: Using general-purpose embeddings with a trained classifier\n",
        "3. **Embedding models + Cosine Similarity**: Zero-shot classification without labeled data\n",
        "\n",
        "We'll work with the Rotten Tomatoes movie review dataset to classify reviews as positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57yEB4v48OnJ",
        "outputId": "49aa3223-5830-44bb-8005-1ed89413bb8d"
      },
      "source": [
        "## Getting Started: Loading the Dataset\n",
        "\n",
        "Let's start by loading the Rotten Tomatoes dataset. This dataset contains movie reviews labeled as positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_iGDZCn8RV8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwg-HSm9xkWK"
      },
      "source": [
        "### Investigate: Explore the Dataset\n",
        "\n",
        "**Exercise**: Before running the code below, predict what you think the structure of the data will be:\n",
        "- What keys will be in each example?\n",
        "- What will the labels look like (what values will they have)?\n",
        "- How many examples are in train vs test?\n",
        "\n",
        "Now let's examine the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BN47a198SRG"
      },
      "source": [
        "---\n",
        "\n",
        "## Section A: Using a Task-specific Model\n",
        "\n",
        "### Introduction to Hugging Face Transformers and Pipelines\n",
        "\n",
        "Before we dive into classification, let's get familiar with **Hugging Face Transformers** - one of the most popular libraries for working with pre-trained language models.\n",
        "\n",
        "#### What is Hugging Face Transformers?\n",
        "\n",
        "**Hugging Face Transformers** is a Python library that provides easy access to thousands of pre-trained models for Natural Language Processing (NLP). These models have been trained on massive amounts of text data and can understand language patterns, making them incredibly powerful for various tasks like:\n",
        "- Text classification (sentiment analysis, spam detection, etc.)\n",
        "- Question answering\n",
        "- Text generation\n",
        "- Translation\n",
        "- And much more!\n",
        "\n",
        "#### What is a Pipeline?\n",
        "\n",
        "A **pipeline** is Hugging Face's high-level API that makes it incredibly easy to use pre-trained models. Think of it as a \"one-stop shop\" that handles all the complex steps for you:\n",
        "\n",
        "1. **Loading the model**: Downloads and loads the pre-trained model\n",
        "2. **Tokenization**: Converts text into numbers the model can understand\n",
        "3. **Inference**: Runs the model to make predictions\n",
        "4. **Post-processing**: Formats the output in a readable way\n",
        "\n",
        "**Why use pipelines?**\n",
        "- **Simplicity**: You can classify text in just a few lines of code\n",
        "- **No deep learning knowledge required**: The pipeline handles all the technical details\n",
        "- **Consistent interface**: Same API for different models and tasks\n",
        "- **Production-ready**: Optimized for real-world use\n",
        "\n",
        "#### A Simple Example\n",
        "\n",
        "Here's what using a pipeline looks like (we'll see this in action soon):\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Use it!\n",
        "result = classifier(\"I love this movie!\")\n",
        "print(result)\n",
        "# Output: [{'label': 'POSITIVE', 'score': 0.9998}]\n",
        "```\n",
        "\n",
        "That's it! No model architecture knowledge, no tokenization code, no manual inference - just simple, powerful text classification.\n",
        "\n",
        "Now let's use this powerful tool to classify our movie reviews!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Phase\n",
        "\n",
        "**Before running the code below, think about:**\n",
        "1. What do you think `pipeline` does? What are its advantages?\n",
        "2. What does `return_all_scores=True` mean?\n",
        "3. Why might we specify `device=\"cuda\"`?\n",
        "4. What will the output format look like?\n",
        "\n",
        "### Run Phase\n",
        "\n",
        "Now let's create our pipeline. We'll use a specific model that's been trained on Twitter data for sentiment analysis:"
      ],
      "metadata": {
        "id": "pHeP9TgSxr7g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOxQqq6UxkWL"
      },
      "source": [
        "Now let's create our pipeline. We'll use a specific model that's been trained on Twitter data for sentiment analysis:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Path to our Hugging Face model\n",
        "# This model was trained on Twitter data for sentiment analysis\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "# Create a pipeline for sentiment analysis\n",
        "# - model: specifies which pre-trained model to use\n",
        "# - tokenizer: converts text to numbers (usually same as model name)\n",
        "# - return_all_scores: returns scores for all classes, not just the top one\n",
        "# - device: \"cuda\" for GPU (faster), \"cpu\" for CPU (works everywhere)\n",
        "pipe = pipeline(\n",
        "    \"sentiment-analysis\",  # The task we want to perform\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    return_all_scores=True,\n",
        "    device=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "id": "IErZX4AYxwPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfe13E67xkWM"
      },
      "source": [
        "Now let's run inference on the entire test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM9cQ28M8VlA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "# Run inference\n",
        "y_pred = []\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
        "    negative_score = output[0][\"score\"]\n",
        "    positive_score = output[2][\"score\"]\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AC-ezxvxkWM"
      },
      "source": [
        "**Investigate**:\n",
        "- Why do we use `output[0]` and `output[2]`? What is `output[1]`?\n",
        "- What does `np.argmax` do? Why do we use it here?\n",
        "- What are the possible values in `y_pred`? How do they map to positive/negative?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i_wnkkc8Wlm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print the classification report\"\"\"\n",
        "    performance = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFnwiq968Xi_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print the classification report\"\"\"\n",
        "    performance = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9bhAQ-mxkWN"
      },
      "source": [
        "Now let's evaluate the performance:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "eQKCPRj8x2iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vw7uvdhxkWN"
      },
      "source": [
        "**Note**: To improve the performance of our selected model, we could do a few different things including selecting a model trained on our domain data, movie reviews in this case, like DistilBERT base uncased finetuned SST-2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRIve2Nj8bDD"
      },
      "source": [
        "---\n",
        "\n",
        "## Section B: Using an Embedding Model + Classifier Head\n",
        "\n",
        "### Introduction to Sentence Transformers\n",
        "\n",
        "However, what if we cannot find a model that was pretrained for this specific task? Do we need to fine-tune a representation model ourselves? The answer is no!\n",
        "\n",
        "There might be times when you want to fine-tune the model yourself if you have sufficient computing available. However, not everyone has access to extensive computing. This is where general-purpose embedding models come in.\n",
        "\n",
        "#### What is Sentence Transformers?\n",
        "\n",
        "**Sentence Transformers** is a Python library built on top of Hugging Face Transformers that specializes in creating **embeddings** - numerical representations of text that capture semantic meaning.\n",
        "\n",
        "The model `sentence-transformers/all-mpnet-base-v2` we'll use:\n",
        "- Maps sentences & paragraphs to a **768-dimensional** dense vector space\n",
        "- Each dimension captures some aspect of the text's meaning\n",
        "- Can be used for tasks like clustering, semantic search, or (as we'll see) classification\n",
        "\n",
        "#### The Strategy: Embeddings + Classifier\n",
        "\n",
        "Instead of using a task-specific model, we'll:\n",
        "1. **Convert text to embeddings** using Sentence Transformers (frozen, no training needed)\n",
        "2. **Train a simple classifier** (like Logistic Regression) on top of these embeddings\n",
        "\n",
        "This approach gives us:\n",
        "- ✅ Flexibility to adapt to any classification task\n",
        "- ✅ Fast training (only the classifier needs training, not the embedding model)\n",
        "- ✅ Good performance with less computational resources\n",
        "- ✅ Ability to reuse embeddings for multiple tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Phase\n",
        "\n",
        "Let's load a Sentence Transformer model and convert our text to embeddings:"
      ],
      "metadata": {
        "id": "KMgbaEukysM5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmRsHKzX8eqY"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load a pre-trained Sentence Transformer model\n",
        "# This model converts text into 768-dimensional vectors\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dboe-V18xkWO"
      },
      "source": [
        "### Investigate Phase\n",
        "\n",
        "**Exercise**: Try encoding a single sentence and examine its embedding. What do you notice about the values?\n",
        "```python\n",
        "# Try this:\n",
        "single_embedding = model.encode(\"This is a test sentence\")\n",
        "print(f\"Shape: {single_embedding.shape}\")\n",
        "print(f\"Sample values: {single_embedding[0][:10]}\")\n",
        "print(f\"Min: {single_embedding.min()}, Max: {single_embedding.max()}\")\n",
        "```\n",
        "\n",
        "**Exercise 3**: Compare embeddings of similar vs different sentences. What patterns do you see?\n",
        "```python\n",
        "# Try this:\n",
        "similar1 = model.encode(\"I love this movie\")\n",
        "similar2 = model.encode(\"This film is amazing\")\n",
        "different = model.encode(\"The weather is nice today\")\n",
        "\n",
        "# Calculate cosine similarity (we'll learn about this in Section C)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(\"Similar sentences:\", cosine_similarity([similar1], [similar2])[0][0])\n",
        "print(\"Different sentences:\", cosine_similarity([similar1], [different])[0][0])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our text data to embeddings\n",
        "# Each review becomes a vector of 768 numbers\n",
        "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
        "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "frsQOD2N1AJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ebTOSsxkWO"
      },
      "source": [
        "Let's check the shape of our embeddings to understand what we've created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axLUc07Q8fmo"
      },
      "outputs": [],
      "source": [
        "train_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llmx6TNWxkWO"
      },
      "source": [
        "Now let's train a simple classifier on top of these embeddings. We'll use Logistic Regression - a fast, interpretable classifier that works well with embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a classifier on embeddings\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
      ],
      "metadata": {
        "id": "elw0ZN2H0xhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now let's evaluate our classifier on the test set:"
      ],
      "metadata": {
        "id": "vIbQ05hN1RiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y_pred = clf.predict(test_embeddings)\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "oZUlmCEt1Sf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOb-gzR3xkWO"
      },
      "source": [
        "**Investigate**:\n",
        "\n",
        "- What are the advantages of this approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkQFtT_kxkWO"
      },
      "source": [
        "**Result**: By training a classifier on top of our embeddings, we managed to get an F1 score of 0.85! This demonstrates the possibilities of training a lightweight classifier while keeping the underlying embedding model frozen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfVc7PNM8kc3"
      },
      "source": [
        "## C. Using just the Embedding Model (headless) + Cosine Similarity\n",
        "\n",
        "**What If We Do Not Have Labeled Data?**\n",
        "\n",
        "Getting labeled data is a resource-intensive task that can require significant human labor. Moreover, is it actually worthwhile to collect these labels?\n",
        "\n",
        "To perform **zero-shot classification** with embeddings, there is a neat trick that we can use. We can describe our labels based on what they should represent. For example, a negative label for movie reviews can be described as “This is a negative movie review.” By describing and embedding the labels and documents, we have data that we can work with. This process, as illustrated in Figure 4-14, allows us to generate our own target labels without the need to actually have any labeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNVJ7ZtH8lc5"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0414.png\" alt=\"Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\">\n",
        "\n",
        "Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAIYOeci8ovh"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for our labels\n",
        "label_embeddings = model.encode([\n",
        "    \"A negative review\",\n",
        "    \"A positive review\"\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqpfbwdj8ppJ"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0415.png\">\n",
        "\n",
        "Figure 4-15. The cosine similarity is the angle between two vectors or embeddings. In this example, we calculate the similarity between a document and the two possible labels, positive and negative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P74dTMFP8quV"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0416.png\" />\n",
        "\n",
        "Figure 4-16. After embedding the label descriptions and the documents, we can use cosine similarity for each label document pair.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwgfyBV-8rcl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find the best matching label for each document\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4WjuMuh8sP7"
      },
      "source": [
        "And that is it! We only needed to come up with names for our labels to perform our classification tasks. Let’s see how well this method works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2btEd8Ab8s9a"
      },
      "outputs": [],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-FGaJsO8t9f"
      },
      "source": [
        "#### Improve our label emeddings\n",
        "\n",
        "Let's try improving our label embeddings by:\n",
        "1. making it more polar by having the word **\"very\"** and\n",
        "2. being more specific by adding the word **\"movie\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpOBewI78uw7"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for our labels\n",
        "label_embeddings = model.encode([\n",
        "    \"A very negative movie review\",\n",
        "    \"A very positive movie review\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlkWpfTe8viI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find the best matching label for each document\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLuxjJJU8wXN"
      },
      "outputs": [],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFS6d0FI8xTd"
      },
      "source": [
        "Do you notice the performance increase?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBR3Idfv8x4j"
      },
      "source": [
        "> The author [(Jay Alammar)](https://jalammar.github.io/) notes that using NLI-based [zero-shot classification](https://huggingface.co/tasks/zero-shot-classification) **is better than using emedding models**. However, this was done to illustrate the **versatility of emedding models**. We will look at **Natural Language Inference (NLI)** in the next notebook Inshallah."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}